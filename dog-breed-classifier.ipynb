{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: azureml-sdk[contrib,notebooks] in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-train==0.1.80.* in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-pipeline==0.1.80.* in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-core==0.1.80.* in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-contrib-server==0.1.80.*; extra == \"contrib\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-contrib-brainwave==0.1.80.*; extra == \"contrib\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-contrib-run==0.1.80.*; extra == \"contrib\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-contrib-tensorboard==0.1.80.*; extra == \"contrib\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-widgets==0.1.80.*; extra == \"notebooks\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-train-core==0.1.80.* in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-train==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-pipeline-core==0.1.80.* in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-pipeline==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-pipeline-steps==0.1.80.* in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-pipeline==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2018.5)\n",
      "Requirement already satisfied, skipping upgrade: azure-storage-blob>=1.1.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-storage>=1.5.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-storage-common>=1.1.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: backports.tempfile in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.0)\n",
      "Requirement already satisfied, skipping upgrade: ndg-httpsclient in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.24,>=1.23 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: azure-storage-nspkg>=3.0.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-containerregistry>=2.0.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.11.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: ruamel.yaml<=0.15.51,>=0.15.35 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.15.51)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.6.4)\n",
      "Requirement already satisfied, skipping upgrade: msrestazure>=0.4.33 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-cli-profile>=2.0.26 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-resource>=1.2.1 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-keyvault>=0.40.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-authorization>=0.40.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.50.0)\n",
      "Requirement already satisfied, skipping upgrade: docker in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (3.5.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-graphrbac>=0.40.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.40.0)\n",
      "Requirement already satisfied, skipping upgrade: msrest>=0.5.1 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.5.4)\n",
      "Requirement already satisfied, skipping upgrade: contextlib2 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.5.5)\n",
      "Requirement already satisfied, skipping upgrade: pathspec in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.5.6)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.1 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.19.1)\n",
      "Requirement already satisfied, skipping upgrade: azure-common>=1.1.12 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.1.14)\n",
      "Requirement already satisfied, skipping upgrade: azure-cli-core>=2.0.38 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.0.43)\n",
      "Requirement already satisfied, skipping upgrade: SecretStorage<3.0.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: jsonpickle in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.9.6)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-contrib-brainwave==0.1.80.*; extra == \"contrib\"->azureml-sdk[contrib,notebooks]) (1.14.1)\n",
      "Requirement already satisfied, skipping upgrade: keras==2.1.5 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-contrib-brainwave==0.1.80.*; extra == \"contrib\"->azureml-sdk[contrib,notebooks]) (2.1.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: ipywidgets>=7.0.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (7.3.1)\n",
      "Requirement already satisfied, skipping upgrade: azureml-telemetry==0.1.80.* in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: azureml-train-restclients-hyperdrive==0.1.80.* in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azureml-train-core==0.1.80.*->azureml-train==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.1.80)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /Users/danielsc/.local/lib/python3.6/site-packages (from azureml-pipeline-steps==0.1.80.*->azureml-pipeline==0.1.80.*->azureml-sdk[contrib,notebooks]) (2018.4.16)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-nspkg>=2.0.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-mgmt-storage>=1.5.0->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: backports.weakref in /Users/danielsc/.local/lib/python3.6/site-packages (from backports.tempfile->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.0.post1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.1 in /Users/danielsc/.local/lib/python3.6/site-packages (from ndg-httpsclient->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: PyOpenSSL in /Users/danielsc/.local/lib/python3.6/site-packages (from ndg-httpsclient->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (18.0.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-nspkg>=2.0.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-storage-nspkg>=3.0.0->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.7 in /Users/danielsc/.local/lib/python3.6/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.11.5)\n",
      "Requirement already satisfied, skipping upgrade: idna>=2.1 in /Users/danielsc/.local/lib/python3.6/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: adal<2.0.0,>=0.6.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from msrestazure>=0.4.33->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: azure-cli-command-modules-nspkg>=2.0.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-profile>=2.0.26->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.3.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from docker->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.3.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client>=0.32.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from docker->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.48.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: isodate>=0.6.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/danielsc/.local/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: tabulate<=0.8.2,>=0.7.7 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.8.2)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=3.13 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: applicationinsights>=0.11.1 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.11.6)\n",
      "Requirement already satisfied, skipping upgrade: paramiko>=2.0.8 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.4.1)\n",
      "Requirement already satisfied, skipping upgrade: knack==0.4.1 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: colorama>=0.3.9 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.3.9)\n",
      "Requirement already satisfied, skipping upgrade: pip in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (18.1)\n",
      "Requirement already satisfied, skipping upgrade: humanfriendly>=4.7 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (4.16.1)\n",
      "Requirement already satisfied, skipping upgrade: azure-cli-nspkg>=2.0.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel==0.30.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.30.0)\n",
      "Requirement already satisfied, skipping upgrade: argcomplete>=1.8.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.9.4)\n",
      "Requirement already satisfied, skipping upgrade: jmespath in /Users/danielsc/.local/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (0.9.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from keras==2.1.5->azureml-contrib-brainwave==0.1.80.*; extra == \"contrib\"->azureml-sdk[contrib,notebooks]) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from keras==2.1.5->azureml-contrib-brainwave==0.1.80.*; extra == \"contrib\"->azureml-sdk[contrib,notebooks]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=4.0.0; python_version >= \"3.3\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (6.5.0)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (4.3.2)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.3.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (3.3.1)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel>=4.5.1 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (4.8.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: pycparser in /Users/danielsc/.local/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.7->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.18)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=0.6.2 in /Users/danielsc/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pynacl>=1.0.1 in /Users/danielsc/.local/lib/python3.6/site-packages (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: bcrypt>=3.1.3 in /Users/danielsc/.local/lib/python3.6/site-packages (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-sdk[contrib,notebooks]) (3.1.4)\n",
      "Requirement already satisfied, skipping upgrade: ipython_genutils in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter_core in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: appnope; sys_platform == \"darwin\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (39.1.0)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (4.3.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.15 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (1.0.15)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (4.6.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.12.1)\n",
      "Requirement already satisfied, skipping upgrade: notebook>=4.4.1 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (5.6.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter_client in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (5.2.3)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (5.1)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.3.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (17.1.0)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (1.0)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: mistune>=0.7.4 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.2.3)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (2.1.3)\n",
      "Requirement already satisfied, skipping upgrade: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.3.0->ipywidgets>=7.0.0->azureml-widgets==0.1.80.*; extra == \"notebooks\"->azureml-sdk[contrib,notebooks]) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "##make sure the latest version is installed. 0.1.80 and restart the kernel\n",
    "!pip install --upgrade azureml-sdk[notebooks,contrib]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (0.14.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from scikit-image) (5.2.0)\n",
      "Requirement already satisfied: networkx>=1.8 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from scikit-image) (2.1)\n",
      "Requirement already satisfied: dask[array]>=0.9.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from scikit-image) (0.20.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/danielsc/.local/lib/python3.6/site-packages (from scikit-image) (1.11.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from scikit-image) (1.0.1)\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from scikit-image) (0.6.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from scikit-image) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from scikit-image) (2.2.2)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from networkx>=1.8->scikit-image) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.11.0; extra == \"array\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from dask[array]>=0.9.0->scikit-image) (1.14.5)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from dask[array]>=0.9.0->scikit-image) (0.9.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image) (1.0.1)\n",
      "Requirement already satisfied: pytz in /Users/danielsc/.local/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image) (2018.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/danielsc/.local/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image) (2.7.3)\n",
      "Requirement already satisfied: setuptools in /Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-image) (39.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.1.80\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dog breed classification using Pytorch Estimators on Azure Machine Learning service\n",
    "\n",
    "Have you ever seen a dog and not been able to tell the breed? Some dogs look so similar, that it can be nearly impossible to tell. For instance these are a few breeds that are difficult to tell apart:\n",
    "\n",
    "#### Alaskan Malamutes vs Siberian Huskies\n",
    "![Image of Alaskan Malamute vs Siberian Husky](http://cdn.akc.org/content/article-body-image/malamutehusky.jpg)\n",
    "\n",
    "#### Whippet vs Italian Greyhound \n",
    "![Image of Whippet vs Italian Greyhound](http://cdn.akc.org/content/article-body-image/whippetitalian.jpg)\n",
    "\n",
    "There are sites like http://what-dog.net, which use Microsoft Cognitive Services to be able to make this easier. \n",
    "\n",
    "In this tutorial, you will learn how to train your own image classification model using transfer learning. The Azure Machine Learning python SDK's [PyTorch estimator](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-pytorch) enables you to easily submit PyTorch training jobs for both single-node and distributed runs on Azure compute. The model is trained to classify dog breeds using a pretrained ResNet18 model that has been trained on the [Stanford Dog dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/). This dataset has been built using images and annotation from ImageNet for the task of fine-grained image categorization. For time, we will use a subset of this dataset which includes 10 dog breeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Azure Machine Learning service?\n",
    "Azure Machine Learning service (Preview) is a cloud service that you can use to develop and deploy machine learning models. Using Azure Machine Learning service, you can track your models as you build, train, deploy, and manage them, all at the broad scale that the cloud provides.\n",
    "![](https://docs.microsoft.com/en-us/azure/machine-learning/service/media/overview-what-is-azure-ml/aml.png)\n",
    "\n",
    "\n",
    "## How can we use it for training image classification models?\n",
    "Training machine learning models, particularly deep neural networks, is often a time- and compute-intensive task. Once you've finished writing your training script and running on a small subset of data on your local machine, you will likely want to scale up your workload.\n",
    "\n",
    "To facilitate training, the Azure Machine Learning Python SDK provides a high-level abstraction, the estimator class, which allows users to easily train their models in the Azure ecosystem. You can create and use an Estimator object to submit any training code you want to run on remote compute, whether it's a single-node run or distributed training across a GPU cluster. For PyTorch and TensorFlow jobs, Azure Machine Learning also provides respective custom PyTorch and TensorFlow estimators to simplify using these frameworks.\n",
    "\n",
    "### Steps to train with a Pytorch Estimator:\n",
    "In this tutorial, we will:\n",
    "- Connect to an Azure Machine Learning service Workspace \n",
    "- Create a remote compute target\n",
    "- Upload your training data (Optional)\n",
    "- Create your training script\n",
    "- Create an Estimator object\n",
    "- Submit your training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Sign up for an [Azure account](https://azure.microsoft.com/en-ca/free/search)\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
    "![](https://docs.microsoft.com/en-us/azure/machine-learning/service/media/concept-azure-machine-learning-architecture/workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "We will provide a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object to use in this tutorial. If you want to use a different subscription, you can enter the information below and create a Workspace. This step checks to see if the workspace is created and writes a `config.json` that can be used to reference the workspace in other notebooks. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`.\n",
    "\n",
    "**You will be asked to login during this step. Please use the AAD credentials provided to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: /Users/danielsc/git/dogbreeds/aml_config/config.json\n",
      "Found the config file in: /Users/danielsc/git/dogbreeds/aml_config/config.json\n",
      "Workspace name: DanielSc\n",
      "Azure region: westeurope\n",
      "Subscription id: 4feb84f6-2c10-4536-9c8a-0a2360eabfc5\n",
      "Resource group: dogbreed-workshop\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "subscription_id = \"4feb84f6-2c10-4536-9c8a-0a2360eabfc5\"\n",
    "resource_group = \"dogbreed-workshop\"\n",
    "workspace_name = \"DanielSc\" ## or use \"pycon-canada-2\"\n",
    "workspace_region = \"westeurope\"\n",
    "\n",
    "ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region,\n",
    "                      create_resource_group = True,\n",
    "                      exist_ok = True)\n",
    "ws.write_config()\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a remote compute target\n",
    "For this tutorial, we already have a  [Azure Batch AI](https://docs.microsoft.com/azure/batch-ai/overview) cluster with a NC6s_v2, P100 GPU machine, created to use as the [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to execute your training script on. \n",
    "\n",
    "This code creates a cluster for you if it does not already exist in your workspace.\n",
    "\n",
    "**Creation of the cluster takes approximately 5 minutes.** If the cluster is already in your workspace this code will skip the cluster creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"p100cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6s_v2', \n",
    "                                                            autoscale_enabled=True,\n",
    "                                                            min_nodes=1, \n",
    "                                                            max_nodes=1)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "    # Use the 'status' property to get a detailed status for the current cluster. \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach the blobstore with the training data to the workspace\n",
    "The dataset we will use consists of ~150 images per class. Some breeds have more, while others have less. Each class has about 100 training images each for dog breeds, with ~50 validation images for each class. We will look at 10 classes in this tutorial.\n",
    "\n",
    "To make the data accessible for remote training, you will need to upload the data from your local machine to the cloud. AML provides a convenient way to do so via a [Datastore](https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data). The datastore provides a mechanism for you to upload/download data, and interact with it from your remote compute targets. It is an abstraction over Azure Storage. The datastore can reference either an Azure Blob container or Azure file share as the underlying storage. \n",
    "\n",
    "You can view the subset of the data used [here](https://github.com/heatherbshapiro/pycon-canada/tree/master/breeds-10). Or download it from [here](https://github.com/heatherbshapiro/pycon-canada/master/breeds-10.zip) as a zip file. **If you already have the breeds datstore attached you can skip the following code and access it through the following code:**\n",
    "\n",
    "`ds= ws.datastores[\"breeds\"]`\n",
    "\n",
    "To attach a blob container as a data store you use the `Datastore.register_azure_blob_container` function. You can copy the statement with the secrets filled in from [here](https://microsoft.sharepoint.com/teams/azuremlnursery/_layouts/OneNote.aspx?id=%2Fteams%2Fazuremlnursery%2FSiteAssets%2FAzure%20ML%20Nursery%20Notebook&wd=target%28Workshop.one%7C265D85D5-44C8-9D40-B556-A31FA098E708%2FDogbreeds%7C62F09F92-105C-7849-AF84-905BEE9F9588%2F%29) (requires Microsoft Employee login).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name='breeds', \n",
    "                                             container_name=<<add container name>>,\n",
    "                                             account_name=<<add account name name>>, \n",
    "                                             account_key=<<add account key ending with ==>>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a reference to the path on the datastore with the training data. We can do so using the `path` method. In the next section, we can then pass this reference to our training script's `--data_dir` argument. We will start with the 10 classes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_85555e14b1bf4cbcb815d6d6e89c9546\n"
     ]
    }
   ],
   "source": [
    "path_on_datastore = 'breeds-10'\n",
    "ds_data = ds.path(path_on_datastore)\n",
    "print(ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Data\n",
    "\n",
    "If you are interested in downloading the data locally, you can run `ds.download(\".\", 'breeds-10')`. This might take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1672"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.download('.', 'breeds-10', show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training script\n",
    "Now you will need to create your training script. In this tutorial, the training script is already provided for you at `pytorch_train.py`. In practice, you should be able to take any custom training script as is and run it with AML without having to modify your code.\n",
    "\n",
    "However, if you would like to use AML's [tracking and metrics](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#metrics) capabilities, you will have to add a small amount of AML code inside your training script. \n",
    "\n",
    "In `pytorch_train.py`, we will log some metrics to our AML run. To do so, we will access the AML run object within the script:\n",
    "```Python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "Further within `pytorch_train.py`, we log the learning rate and momentum parameters, the best validation accuracy the model achieves, and the number of classes in the model:\n",
    "```Python\n",
    "run.log('lr', np.float(learning_rate))\n",
    "run.log('momentum', np.float(momentum))\n",
    "run.log('num_classes', num_classes)\n",
    "\n",
    "run.log('best_val_acc', np.float(best_acc))\n",
    "```\n",
    "\n",
    "If you downloaded the data, you can start to train the model locally (note that it will take long if you don't have a GPU -- 21 min. on a Core i7 CPU).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data directory is: breeds-10\n",
      "Attempted to log scalar metric lr:\n",
      "0.001\n",
      "Attempted to log scalar metric momentum:\n",
      "0.9\n",
      "Attempted to log scalar metric num_classes:\n",
      "10\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.6437 Acc: 0.4320\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.0\n",
      "val Loss: 0.5329 Acc: 0.7958\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.7958271236959762\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.0900 Acc: 0.6160\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.7958271236959762\n",
      "val Loss: 0.4569 Acc: 0.8241\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8241430700447094\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.0286 Acc: 0.6520\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8241430700447094\n",
      "val Loss: 0.3271 Acc: 0.8644\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8643815201192251\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.9607 Acc: 0.6760\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8643815201192251\n",
      "val Loss: 0.4024 Acc: 0.8346\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8643815201192251\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.9076 Acc: 0.6810\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8643815201192251\n",
      "val Loss: 0.3267 Acc: 0.8763\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8763040238450075\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.9483 Acc: 0.6750\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8763040238450075\n",
      "val Loss: 0.3616 Acc: 0.8554\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8763040238450075\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.9918 Acc: 0.6510\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8763040238450075\n",
      "val Loss: 0.5032 Acc: 0.8197\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8763040238450075\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.8497 Acc: 0.7080\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.8763040238450075\n",
      "val Loss: 0.3264 Acc: 0.8793\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.879284649776453\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.8385 Acc: 0.7060\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.879284649776453\n",
      "val Loss: 0.3167 Acc: 0.8867\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.886736214605067\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.8026 Acc: 0.7280\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.886736214605067\n",
      "val Loss: 0.3228 Acc: 0.8808\n",
      "Attempted to log scalar metric best_val_acc:\n",
      "0.886736214605067\n",
      "\n",
      "Training complete in 21m 0s\n",
      "Best val Acc: 0.886736\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p outputs\n",
    "!python pytorch_train.py --data_dir breeds-10 --num_epochs 10 --output_dir outputs --mode fine_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on the remote compute\n",
    "Now that you have your data and training script prepared, you are ready to train on your remote compute cluster. You can take advantage of Azure compute to leverage GPUs to cut down your training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this transfer learning PyTorch tutorial. \n",
    "\n",
    "**Please enter your own unique name so that you can track your specific runs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch-dogs-ds' ## An example would be \"pytorch-dogs-hs\"\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a PyTorch estimator\n",
    "The AML SDK's PyTorch estimator enables you to easily submit PyTorch training jobs for both single-node and distributed runs. For more information on the PyTorch estimator, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-pytorch). The following code will define a single-node PyTorch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##BATCH AI\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--data_dir': ds_data.as_mount(),\n",
    "    '--num_epochs': 10,\n",
    "    '--output_dir': './outputs',\n",
    "    '--mode': 'fine_tune'\n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory='.', \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target, \n",
    "                    entry_script='pytorch_train.py',\n",
    "                    use_gpu=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `script_params` parameter is a dictionary containing the command-line arguments to your training script `entry_script`. Please note the following:\n",
    "- We passed our training data reference `ds_data` to our script's `--data_dir` argument. This will 1) mount our datastore on the remote compute and 2) provide the path to the training data `breeds` on our datastore.\n",
    "- We specified the output directory as `./outputs`. The `outputs` directory is specially treated by AML in that all the content in this directory gets uploaded to your workspace as part of your run history. The files written to this directory are therefore accessible even once your remote run is over. In this tutorial, we will save our trained model to this output directory.\n",
    "\n",
    "To leverage the Azure VM's GPU for training, we set `use_gpu=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor your run\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa5d96622fd4450b44f58351d4c0ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on 120 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = ds.path('breeds')\n",
    "print(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BATCH AI\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--data_dir': full_dataset.as_mount(),\n",
    "    '--num_epochs': 10,\n",
    "    '--output_dir': './outputs'\n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory=project_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target, \n",
    "                    entry_script='pytorch_train.py',\n",
    "                    use_gpu=True)\n",
    "\n",
    "run = experiment.submit(estimator)\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the web service on model with 120 classes\n",
    "The run will take a few minutes to run on a Standard_NC6s_v2 VM with one node per job. You can also test images against a model that was trained the same way with 120 classes instead of 10. We will send the data as a JSON string to the web service hosted in ACI and use the SDK's `run` API to invoke the service. Here we will take an arbitrary image from our validation data to predict on.\n",
    "\n",
    "**If at any point throughout the process you want to test an existing webservice while you wait, please try out the `webservice-test.ipynb`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing the requests library \n",
    "import requests \n",
    "import os, json, base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "##Get random dog\n",
    "def get_random_dog():\n",
    "    r = requests.get(url =\"https://dog.ceo/api/breeds/image/random\")\n",
    "    URL= r.json()['message']\n",
    "    return URL\n",
    "\n",
    "##Get Random Dog Image\n",
    "URL = get_random_dog()\n",
    "\n",
    "##whippet Example \n",
    "# URL=\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12223018/Whippet-On-White-03.jpg\"\n",
    "\n",
    "##italian greyhound Example\n",
    "# URL=\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12231757/Italian-Greyhound-On-White-03.jpg\"\n",
    "\n",
    "##chihuahua Example\n",
    "# URL =\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12213613/Chihuahua-onWhite-13.jpg\"\n",
    "\n",
    "with urllib.request.urlopen(URL) as url:\n",
    "    test_img = io.BytesIO(url.read())\n",
    "\n",
    "# ## If you downloaded the dataset, you can try this arbitrary image from the test dataset\n",
    "# # test_img = os.path.join('breeds-10', 'val', 'n02085620-Chihuahua', 'n02085620_1271.jpg') \n",
    "\n",
    "plt.imshow(Image.open(test_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def imgToBase64(img):\n",
    "    \"\"\"Convert pillow image to base64-encoded image\"\"\"\n",
    "    imgio = BytesIO()\n",
    "    img.save(imgio, 'JPEG')\n",
    "    img_str = base64.b64encode(imgio.getvalue())\n",
    "    return img_str.decode('utf-8')\n",
    "\n",
    "base64Img = imgToBase64(Image.open(test_img))\n",
    "# api-endpoint \n",
    "scoringURI = \"http://137.117.58.22:80/score\"\n",
    "\n",
    "data = {'data':base64Img} \n",
    "headers = {'content-type': 'application/json'}\n",
    "    \n",
    "# sending post request and saving response as response object \n",
    "r = requests.post(url = scoringURI, data=json.dumps(data), headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model\n",
    "Once the run completes, we can register the model that was created.\n",
    "\n",
    "**Please use a unique name for the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## if you need to reference the run object specifically uncomment this section\n",
    "\n",
    "# from azureml.core import Run\n",
    "# run = Run(experiment, run_id=\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='dog10', model_path = 'outputs/model.pt')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model as web service\n",
    "Once you have your trained model, you can deploy the model on Azure. You can deploy your trained model as a web service on Azure Container Instances (ACI), Azure Kubernetes Service (AKS), IoT edge device, or field programmable gate arrays (FPGAs)\n",
    "\n",
    "ACI is generally cheaper than AKS and can be set up in 4-6 lines of code. ACI is the perfect option for testing deployments. Later, when you're ready to use your models and web services for high-scale, production usage, you can deploy them to AKS.\n",
    "\n",
    "\n",
    "In this tutorial, we will deploy the model as a web service in [Azure Container Instances](https://docs.microsoft.com/en-us/azure/container-instances/) (ACI). \n",
    "\n",
    "\n",
    "For more information on deploying models using Azure ML, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scoring script\n",
    "\n",
    "First, we will create a scoring script that will be invoked by the web service call. Note that the scoring script must have two required functions:\n",
    "* `init()`: In this function, you typically load the model into a `global` object. This function is executed only once when the Docker container is started. \n",
    "* `run(input_data)`: In this function, the model is used to predict a value based on the input data. The input and output typically use JSON as serialization and deserialization format, but you are not limited to that.\n",
    "\n",
    "Refer to the scoring script `pytorch_score.py` for this tutorial. Our web service will use this file to predict whether an image is an ant or a bee. When writing your own scoring script, don't forget to test it locally first before you go and deploy the web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment file\n",
    "Then, we will need to create an environment file (`myenv.yml`) that specifies all of the scoring script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image by AML. In this case, we need to specify `torch`, `torchvision`, `pillow`, and `azureml-sdk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile myenv.yml\n",
    "name: myenv\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - torch\n",
    "    - torchvision\n",
    "    - pillow\n",
    "    - azureml-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the container image\n",
    "Now configure the Docker image that you will use to build your ACI container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script='pytorch_score.py', \n",
    "                                                  runtime='python', \n",
    "                                                  conda_file='myenv.yml',\n",
    "                                                  description='Image with dog breed model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the ACI container\n",
    "We are almost ready to deploy. Create a deployment configuration file to specify the number of CPUs and gigabytes of RAM needed for your ACI container. While it depends on your model, the default of `1` core and `1` gigabyte of RAM is usually sufficient for many models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={'data': 'dog_breeds',  'method':'transfer learning', 'framework':'pytorch'},\n",
    "                                               description='Classify dog breeds using transfer learning with PyTorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the registered model\n",
    "Finally, let's deploy a web service from our registered model. First, retrieve the model from your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = ws.models['dog10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, deploy the web service using the ACI config and image config files created in the previous steps. We pass the `model` object in a list to the `models` parameter. If you would like to deploy more than one registered model, append the additional models to this list.\n",
    "\n",
    "** Please use a unique service name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service_name = 'dog10a'\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       name=service_name,\n",
    "                                       models=[model],\n",
    "                                       image_config=image_config,\n",
    "                                       deployment_config=aciconfig,)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your deployment fails for any reason and you need to redeploy, make sure to delete the service before you do so: `service.delete()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip: If something goes wrong with the deployment, the first thing to look at is the logs from the service by running the following command:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "service.get_logs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the web service\n",
    "Finally, let's test our deployed web service. We will send the data as a JSON string to the web service hosted in ACI and use the SDK's `run` API to invoke the service. Here we will take an arbitrary image from online to predict on. This is the same as above, but now we are testing on our own trained model. You can use any dog image, but please remember we only trained on 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "##Get random dog\n",
    "def get_random_dog():\n",
    "    r = requests.get(url =\"https://dog.ceo/api/breeds/image/random\")\n",
    "    URL= r.json()['message']\n",
    "    return URL\n",
    "\n",
    "##Get Random Dog Image\n",
    "URL = get_random_dog()\n",
    "\n",
    "##whippet Example \n",
    "# URL=\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12223018/Whippet-On-White-03.jpg\"\n",
    "\n",
    "##italian greyhound Example\n",
    "# URL=\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12231757/Italian-Greyhound-On-White-03.jpg\"\n",
    "\n",
    "##chihuahua Example\n",
    "# URL =\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12213613/Chihuahua-onWhite-13.jpg\"\n",
    "\n",
    "with urllib.request.urlopen(URL) as url:\n",
    "    test_img = io.BytesIO(url.read())\n",
    "\n",
    "# ## If you downloaded the dataset, you can try this arbitrary image from the test dataset\n",
    "# # test_img = os.path.join('breeds-10', 'val', 'n02085620-Chihuahua', 'n02085620_1271.jpg') \n",
    "\n",
    "plt.imshow(Image.open(test_img))\n",
    "\n",
    "##whippet\n",
    "# URL=\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12223018/Whippet-On-White-03.jpg\"\n",
    "\n",
    "##italian greyhound\n",
    "# URL=\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12231757/Italian-Greyhound-On-White-03.jpg\"\n",
    "\n",
    "\n",
    "with urllib.request.urlopen(URL) as url:\n",
    "    test_img = io.BytesIO(url.read())\n",
    "\n",
    "plt.imshow(Image.open(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def imgToBase64(img):\n",
    "    \"\"\"Convert pillow image to base64-encoded image\"\"\"\n",
    "    imgio = BytesIO()\n",
    "    img.save(imgio, 'JPEG')\n",
    "    img_str = base64.b64encode(imgio.getvalue())\n",
    "    return img_str.decode('utf-8')\n",
    "\n",
    "base64Img = imgToBase64(Image.open(test_img))\n",
    "\n",
    "result = service.run(input_data=json.dumps({'data': base64Img}))\n",
    "print(json.loads(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete web service\n",
    "Once you no longer need the web service, you should delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:preview]",
   "language": "python",
   "name": "conda-env-preview-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
